---
date: 2026-02-19
tags:
  - type/note
  - status/completed
  - ai/tts
  - dev/python
  - project/yas
  - #daily
created: 2026-02-19
summary: Qwen3-TTS 로컬 음성 합성 서버 구축 완료 + 유튜브 대본 TTS 첫 실전 적용
---

# 📓 AI 활용 일지 — 2026-02-19 (수)

> **오늘의 핵심**: 로컬 AI TTS 서버를 처음부터 구축하고, 실제 유튜브 대본에 적용하기까지의 전 과정

---

## 1. 개요

| 항목 | 내용 |
|------|------|
| 날짜 | 2026-02-19 (수) |
| 주요 성과 | Qwen3-TTS 서버 구축 완료, 유튜브 대본 TTS 첫 생성 |
| 사용 도구 | Qwen3-TTS 1.7B, Python/FastAPI, GTX 1060 6GB |
| 작업 인원 | 존 + 웬디(AI 어시스턴트) |

---

## 2. Qwen3-TTS 서버 구축

### 2-1. 배경 및 목적

- 기존 TTS 서비스(ElevenLabs 등)는 API 비용 발생 + 인터넷 의존
- **로컬 GPU 서버**로 무제한 음성 생성 환경 구축 목표
- 서버 PC: `192.168.0.2` (GTX 1060 6GB)

### 2-2. 모델 선택 과정

| 모델 | 결과 | 원인 |
|------|------|------|
| Qwen3-TTS 0.6B | ❌ 실패 | `CUDA assert input[0] != 0` 오류 |
| Qwen3-TTS 1.7B-Base (float16) | ✅ 성공 | 안정적 동작 확인 |

- **결론**: 1.7B-Base 모델이 GTX 1060 6GB 환경에서 안정적

### 2-3. 아키텍처 설계

```
[존/웬디 PC] ──API 요청──▶ [서버 PC 192.168.0.2:7860]
                              │
                              ├─ Qwen3-TTS 모델 (1.7B)
                              └─ 음성 파일 생성
                                    │
                            [결과 저장 경로]
                    C:\qwen-tts-server\output\
                    └── {날짜}_{프로젝트명}\
                         └── 001_요약.wav
```

- 역할 분리: 서버 PC = 생성 전담, 웬디 PC = API 요청 + 파일 저장 관리
- API 키: `.env` 파일로 보안 관리

### 2-4. 핵심 버그 해결: 끝 글자 잘림 문제

**문제 현상**
- TTS 생성 시 마지막 1~2글자가 잘려서 출력됨
- 예: "안녕하세요" → "안녕하세" 로 잘림

**원인 분석**
- 모델이 문장 끝에 충분한 토큰을 생성하지 않는 구조적 문제

**해결 방법** ✅
1. 원본 텍스트 뒤에 **더미 텍스트** 추가
   ```
   원본 텍스트 + "...그리고 잠시 쉬어가겠습니다."
   ```
2. 생성된 오디오에서 **무음 구간(silence)** 감지
3. 무음 직전 지점을 cut point로 삼아 정확하게 자르기

**왜 비율 기반 자르기는 안 되나?**
- 문장마다 말하는 속도가 달라 비율이 부정확
- 무음 감지가 실제 발화 종료 지점을 가장 정확히 포착

### 2-5. 트러블슈팅 기록

| 오류 | 원인 | 해결책 |
|------|------|--------|
| `CUDA assert input[0] != 0` | 0.6B 모델 토크나이저 이슈 | 1.7B 모델로 교체 |
| `latin-1 인코딩 오류` | HTTP 헤더에 한글 포함 | 헤더에서 한글 제거 |
| `Torch not compiled with CUDA enabled` | venv 밖에서 실행 | 반드시 venv 활성화 후 실행 |
| "。" 패딩 실패 | 토크나이저 한자 패딩 호환 안 됨 | 더미 텍스트 방식으로 교체 |

---

## 3. 유튜브 대본 TTS 첫 실전 적용

### 3-1. 작업 내용
- **주제**: AI 운영 관련 유튜브 쇼츠 대본
- **문장 수**: 23문장
- **총 길이**: 약 90초 분량
- **저장 경로**: `C:\qwen-tts-server\output\2026-02-19_AI운영-유튜브대본\`

### 3-2. 워크플로우
```
대본 작성 (텍스트)
    ↓
문장 단위 분리
    ↓
Qwen3-TTS API 요청 (더미 텍스트 포함)
    ↓
무음 감지 → 정확한 cut
    ↓
001.wav, 002.wav ... 순서 저장
    ↓
영상 편집 시 활용
```

---

## 4. 코드 저장소

- **GitHub**: https://github.com/keyfream7001/qwen3-tts-server (private)
- **옵시디언 가이드**: `300 Resources/Qwen3-TTS 완전 가이드.md`

---

## 5. 핵심 배운 점

1. **로컬 TTS의 가능성**: GTX 1060 6GB로도 충분히 실용적인 TTS 서버 구동 가능
2. **끝 잘림 문제는 더미 텍스트 + 무음 감지로 해결** — 이 패턴은 다른 TTS 모델에도 적용 가능
3. **모델 크기와 안정성**: 작은 모델(0.6B)이 항상 좋은 건 아님, 하드웨어 호환성 중요
4. **API 설계**: 생성 서버와 저장/관리 서버를 분리하면 유지보수 용이

---

## 6. 다음 할 일

- [ ] Qwen3-TTS 서버 성능 테스트 (동시 요청 처리)
- [ ] Project YAS에 TTS 파이프라인 통합
- [ ] 음성 클론(Voice Clone) 기능 실험
- [ ] 서버 PC 항상 켜두는 방법 자동화 (Wake-on-LAN)

---

*작성: 웬디 (AI 어시스턴트) | 검토: 존*
