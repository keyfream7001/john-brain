---
date: 2026-02-20
tags:
  - type/note
  - status/inProgress
  - ai/agents
  - dev/python
  - #blog
created: 2026-02-20
summary: 하루 만에 집 서버 PC + 안드로이드 폰 + 맥북을 AI 네트워크로 연결한 이야기
---

# 🌐 하루 만에 집 안의 모든 기기를 AI 비서 네트워크로 연결했다

> "웬디야, 지금 내 폰으로도 명령 보낼 수 있어?"
> "네, 안드로이드 노드 연결 완료됐어요. 폰 카메라도 제어 가능해요."

이 대화가 가능해진 날, 2026년 2월 20일의 이야기입니다.

---

## 아침부터 시작된 인프라 정비

사실 이날은 원래 유튜브 자동화 시스템(Project YAS) 작업을 이어가려고 했어요. 근데 먼저 밀린 인프라 정비를 해야 했습니다.

**OpenClaw가 업데이트됐거든요.**

`2026.2.6-3` → `2026.2.19-2`, 무려 두 달치 업데이트. 여기서 제일 반가웠던 건 **Claude Sonnet 4.6 지원** 추가였어요. 그동안 쓰던 모델보다 확실히 빠르고 정확해진 느낌이라 기대가 됩니다.

맥북도 OpenClaw 노드로 재연결하고, 이제 "맥북으로 말해줘" 하면 실제로 맥 스피커에서 AI 목소리가 나오는 세팅까지 완성. (서비스 모드 타임아웃 이슈는 있는데 그건 나중에...)

---

## 서버 PC를 AI 실험실로 만들기

집에 굴러다니는 GTX 1060 6GB 서버 PC. 어제는 Qwen3-TTS 서버로 썼는데, 오늘은 더 본격적으로 **AI 도구 실행 전용 노드**로 세팅하기로 했어요.

Tailscale로 VPN 연결하고, OpenClaw 노드 연결하고, 그 다음이 진짜였어요.

**AI 도구 6종 설치:**
- 🎤 **faster-whisper** — 음성을 텍스트로 (STT)
- ✂️ **rembg** — 배경 제거
- 👁️ **YOLOv11** — 객체 감지
- 📝 **PaddleOCR** — 이미지에서 텍스트 추출
- 🖼️ **Real-ESRGAN** — 이미지 업스케일링
- 👤 **InsightFace** — 얼굴 분석

그냥 리스트로 보면 별거 아닌 것 같지만, 이게 다 **웹 API 없이 로컬에서 돌아간다**는 게 핵심이에요. 인터넷 연결 없어도, 비용 없이, 무제한으로.

### 중간에 만난 함정: Python 3.13 호환성

Real-ESRGAN이랑 InsightFace는 Python 3.13에서 빌드가 안 돼요. C 확장 패키지들이라 3.13의 변경사항과 충돌이 있거든요.

해결책은 **Python 3.11 가상환경 별도 생성**. 그리고 basicsr 라이브러리의 import 오류도 직접 코드 한 줄 수정해야 했어요.

이런 거 하나씩 뚫을 때마다 느끼는 건데... 삽질이 쌓이면 결국 자산이 되더라고요. 지금은 이 패턴 완전히 이해했으니까 다음엔 5분 만에 해결합니다.

---

## 오후의 메인 이벤트: 안드로이드 폰 연결 대작전

점심 먹고 시작한 게 **안드로이드 폰에 OpenClaw 노드 설치**였어요.

솔직히 말하면... 이거 쉽지 않았습니다.

### 1차 시도: Termux 직접 설치 → 실패

Termux에서 `npm install -g openclaw` 했더니?

```
Error: koffi/spawn.h: No such file or directory
```

이 오류의 정체는 **Bionic libc 호환성 문제**. Android의 Bionic은 GNU libc가 아니라서 Node.js 네이티브 모듈들이 빌드가 안 되는 경우가 많아요.

### 2차 시도: proot-distro Ubuntu → 성공! ✅

해결책은 **Termux 안에서 Ubuntu를 돌리는 것**이었어요.

`proot-distro`라는 도구로 Ubuntu 환경을 만들고, 그 안에서 Node.js 설치하고, OpenClaw 설치하면 됩니다. 이 안에서는 진짜 Linux 환경이니까 모든 게 정상적으로 작동해요.

```
openclaw --version
2026.2.19-2
```

터미널에 이 글자 뜨는 순간 진짜 뿌듯했어요.

---

## 그러다 만난 가장 황당한 버그

안드로이드 노드를 게이트웨이에 연결하려는데... 갑자기 모든 게 안 됩니다.

```
pairing required (1008)
```

맥북도, 서버 PC도, CLI도 다 이 오류. 뭔가 하다가 게이트웨이를 재시작한 게 원인이었어요.

알고 보니 **OpenClaw의 버그**: 게이트웨이를 재시작하면 `devices/paired.json`이 `{}`로 초기화됩니다. 모든 페어링 정보가 날아가는 거예요.

수동으로 파일 편집해봤지만 소용없었어요. 재시작하면 또 초기화되니까요.

**해결책은 의외로 단순했어요:**

1. `openclaw dashboard` 실행
2. 브라우저 대시보드 열기
3. **Nodes 탭 → Approve** 버튼 클릭

그냥 UI에서 승인 버튼 누르는 거였어요. 근데 이걸 찾는 데 거의 30분 걸렸습니다 😅

---

## 저녁: 모든 게 연결되다

그 뒤로는 착착 진행됐어요.

안드로이드 폰은 Tailscale IP `100.77.239.13`으로 페어링 완료. 이제 웬디가 폰에 명령을 보낼 수 있어요.

그리고 **Termux:API 브릿지**도 연결했는데, 이게 하이라이트예요. 이걸 통해서 폰의 40가지 기능에 접근할 수 있게 됩니다:

- 폰 카메라로 사진 찍기
- 배터리 상태 확인
- 알림 보내기
- SMS 읽기 (물론 허용한 것만)
- 그리고... TTS (폰에서 직접 음성으로 말하기)

TTS는 proot 안에서 termux-tts-speak를 접근하는 게 좀 복잡해서 바인드마운트 방식으로 다음에 추가로 구현하기로 했어요.

---

## 하루를 마치며: 웬디의 하드웨어 생태계

이날 작성한 `웬디 하드웨어 생태계 - 인프라 기술서` 문서에 Mermaid 다이어그램으로 전체 구조를 정리했는데, 보기만 해도 뿌듯합니다.

```
웬디(AI 비서)
├── 윈도우 메인 PC (기본 작업)
├── 맥북 (TTS 출력 + 시리 연동)
├── AI 서버 PC (Whisper·rembg·YOLO·OCR·Upscale·Face)
└── 안드로이드 폰 (카메라·알림·SMS·TTS)
```

모두 Tailscale VPN으로 연결되고, OpenClaw 게이트웨이로 통합됩니다.

하루 만에 이 구조가 완성됐어요. 삽질도 많았지만 그래서 더 의미 있는 것 같아요.

다음 목표는 이 인프라 위에서 **Project YAS(유튜브 자동화 시스템)**를 본격 가동하는 것입니다.

---

*더 궁금한 점 있으시면 댓글로 물어봐 주세요! 🙌*
